## Neuromatch Group: "Quantrek"

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

Overarching Question: What are the encoding differences between images (maybe videos) with a clear living subject (humans, animals etc) vs. frames of the videos without that feature? BONUS: In the frames without a clear subject, is there an identifiable period of time where the participant needs to mentally search for a subject?


![alt text](https://github.com/clachevv/neuro-match-project/blob/main/pictures/pic.png)



